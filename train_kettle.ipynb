{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import base64\n",
    "import imageio\n",
    "import IPython\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import pyvirtualdisplay\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tf_agents.agents.dqn import dqn_agent\n",
    "from tf_agents.drivers import dynamic_step_driver\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.networks import q_network\n",
    "from tf_agents.policies import random_tf_policy\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.trajectories import trajectory\n",
    "from tf_agents.utils import common\n",
    "\n",
    "from tf_agents.environments import py_environment\n",
    "from tf_agents.environments import tf_environment\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.environments import utils\n",
    "from tf_agents.specs import array_spec\n",
    "from tf_agents.environments import wrappers\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "\n",
    "USE_SIMULATION = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.enable_v2_behavior()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.version.VERSION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations = 200000 # @param {type:\"integer\"}\n",
    "\n",
    "initial_collect_steps = 10  # @param {type:\"integer\"} \n",
    "collect_steps_per_iteration = 1  # @param {type:\"integer\"}\n",
    "replay_buffer_max_length = 100000  # @param {type:\"integer\"}\n",
    "\n",
    "batch_size = 16  # @param {type:\"integer\"}\n",
    "learning_rate = 1e-5  # @param {type:\"number\"}\n",
    "log_interval = 1000  # @param {type:\"integer\"}\n",
    "\n",
    "num_eval_episodes = 10  # @param {type:\"integer\"}\n",
    "eval_interval = 1000  # @param {type:\"integer\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions for the real kettle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def observe_kettle():\n",
    "    # TODO remove the offset!!\n",
    "    resp = requests.get(\"http://192.168.178.87/\")\n",
    "    a = json.loads(resp.text)\n",
    "    temperatures = [x[1]-50.0 for x in json.loads(resp.text)[\"temp\"]]\n",
    "    on_off = [float(x[1]) for x in json.loads(resp.text)[\"state\"]]\n",
    "    return temperatures+on_off\n",
    "\n",
    "def turn_kettle_on():    \n",
    "    resp = requests.get(\"http://192.168.178.87/r_on\")\n",
    "    \n",
    "def turn_kettle_off():    \n",
    "    resp = requests.get(\"http://192.168.178.87/r_off\")\n",
    "\n",
    "    \n",
    "# observation = observe_kettle()\n",
    "# print(observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulated kettle environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class KettleEnv(py_environment.PyEnvironment):\n",
    "  def __init__(self):\n",
    "    self._action_spec = array_spec.BoundedArraySpec(shape=(), dtype=np.int32, minimum=0, maximum=1, name='action')\n",
    "    self._observation_spec = array_spec.BoundedArraySpec(shape=(20,), dtype=np.float32, minimum=0, name='observation')\n",
    "    self._state = 0\n",
    "    self._episode_ended = False\n",
    "\n",
    "  def action_spec(self):\n",
    "    return self._action_spec\n",
    "\n",
    "  def observation_spec(self):\n",
    "    return self._observation_spec\n",
    "\n",
    "  def _reset(self):\n",
    "    # TODO print something for me to clean out the kettle...\n",
    "    self._state = observe_kettle()\n",
    "    self._episode_ended = False\n",
    "    return ts.restart(np.array(self._state, dtype=np.float32))\n",
    "\n",
    "  def _step(self, action):\n",
    "    if self._episode_ended:\n",
    "      # The last action ended the episode. Ignore the current action and start a new episode.\n",
    "      return self.reset()\n",
    "\n",
    "    # Make sure episodes don't go on forever.\n",
    "    if action == 1:\n",
    "        turn_kettle_on()\n",
    "    elif action == 0:\n",
    "        turn_kettle_off()\n",
    "    else:\n",
    "      raise ValueError('`action` should be 0 or 1.')\n",
    "\n",
    "    # TODO do I have to sleep here or somewhere else...\n",
    "    time.sleep(1.0)\n",
    "    \n",
    "    self._state = observe_kettle()\n",
    "\n",
    "    current_temp = self._state[9]\n",
    "    print(\"Current temp\", current_temp)\n",
    "    given_reward = 0.0\n",
    "    if current_temp < 0:\n",
    "        given_reward = 1.0-0.0*abs(current_temp)\n",
    "    else:\n",
    "        given_reward = 1.0-0.03*abs(current_temp)\n",
    "    \n",
    "    return ts.transition(np.array(self._state, dtype=np.float32), reward=given_reward, discount=1.0)\n",
    "\n",
    "\n",
    "\n",
    "class SimulatedKettleEnv(py_environment.PyEnvironment):\n",
    "  def __init__(self):    \n",
    "    self.action_history_seconds = 100\n",
    "    self.set_temperature = 50.0\n",
    "        \n",
    "    # Actions the neural network can take. In this caes it's either 0 or 1. \n",
    "    self._action_spec = array_spec.BoundedArraySpec(shape=(), dtype=np.int32, minimum=0, maximum=1, name='action')\n",
    "    \n",
    "    # The observations the neural network makes. In this case it consists of: \n",
    "    #   * a certain length of history in temperatures in seconds\n",
    "    #   * a certain length of history in temperatures in action-performed (0 or 1)\n",
    "    self._observation_spec = array_spec.BoundedArraySpec(shape=(2*self.action_history_seconds,), dtype=np.float32, minimum=0, name='observation')\n",
    "\n",
    "    # Some other things. \n",
    "    self._state = 0\n",
    "    self._episode_ended = False\n",
    "\n",
    "  def action_spec(self):\n",
    "    return self._action_spec\n",
    "\n",
    "  def observation_spec(self):\n",
    "    return self._observation_spec\n",
    "\n",
    "  def _update_state(self):\n",
    "            # The current state consists of two things: \n",
    "#     self._state = self.water_history[-self.action_history_seconds:] + self.action_history[-self.action_history_seconds:]\n",
    "    self._state = [0.01*(x-self.set_temperature) for x in self.water_history[-self.action_history_seconds:]] + self.action_history[-self.action_history_seconds:]\n",
    "    \n",
    "  def _reset(self):\n",
    "    print(\"Resetting the kettle\")\n",
    "    # Reset the model of the rod and the water\n",
    "    self.temperature_rod = 20.0\n",
    "    self.temperature_water = 20.0\n",
    "    \n",
    "    # Reset the parameters which determine the state\n",
    "    self.water_history = [self.temperature_water]*self.action_history_seconds\n",
    "    self.action_history = [0.0]*self.action_history_seconds # pretend we did not do anything for a while\n",
    "    \n",
    "    self._update_state()\n",
    "\n",
    "    \n",
    "    self._episode_ended = False\n",
    "    return ts.restart(np.array(self._state, dtype=np.float32))\n",
    "\n",
    "  def _step(self, action):\n",
    "    if self._episode_ended:\n",
    "      # The last action ended the episode. Ignore the current action and start a new episode.\n",
    "      return self.reset()\n",
    "\n",
    "    # TODO implement a better mathematical model, such as this one: https://www.ijesm.co.in/uploads/68/5720_pdf.pdf\n",
    "    if action == 1:\n",
    "        self.temperature_water += 0.1\n",
    "    elif action == 0:\n",
    "        # don't do anything, rod will cool down anyways\n",
    "        self.temperature_water -= 0.1\n",
    "    else:\n",
    "      raise ValueError('`action` should be 0 or 1.')\n",
    "\n",
    "    \n",
    "    # Add the temperature of the water and the performed action\n",
    "    self.water_history.append(self.temperature_water)\n",
    "    self.action_history.append(float(action))\n",
    "    \n",
    "    self._update_state()\n",
    "    \n",
    "    # TODO Very ugly way to get the temperature to set_temp degrees...\n",
    "#     print(\"Current temp\", self.temperature_water, ' action was ', action)\n",
    "    current_temp = self.temperature_water - self.set_temperature\n",
    "\n",
    "\n",
    "    given_reward = 0.0\n",
    "    if current_temp < 0:\n",
    "        given_reward = 1.0-0.01*abs(current_temp)\n",
    "    else:\n",
    "        given_reward = 1.0-0.03*abs(current_temp)\n",
    "    \n",
    "    if self.temperature_water > 90.0 or self.temperature_water < 0.0:\n",
    "        # This is too hot, better cool down a bit\n",
    "        self._episode_ended = True\n",
    "        return ts.termination(np.array(self._state, dtype=np.float32), given_reward)\n",
    "    else:\n",
    "        return ts.transition(np.array(self._state, dtype=np.float32), reward=given_reward, discount=1.0)\n",
    "    \n",
    "if USE_SIMULATION:\n",
    "    env = SimulatedKettleEnv()\n",
    "else:\n",
    "    env = KettleEnv()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resetting the kettle\n",
      "0.701\n",
      "0.702\n",
      "0.703\n",
      "0.704\n",
      "0.705\n",
      "0.706\n",
      "0.707\n",
      "0.708\n",
      "0.709\n",
      "0.71\n",
      "0.711\n",
      "0.712\n",
      "0.713\n",
      "0.714\n",
      "0.715\n",
      "0.716\n",
      "0.717\n",
      "0.718\n",
      "0.719\n",
      "0.72\n",
      "0.721\n",
      "0.722\n",
      "0.723\n",
      "0.724\n",
      "0.725\n",
      "0.726\n",
      "0.727\n",
      "0.728\n",
      "0.729\n",
      "0.73\n",
      "0.731\n",
      "0.732\n",
      "0.733\n",
      "0.734\n",
      "0.735\n",
      "0.736\n",
      "0.737\n",
      "0.738\n",
      "0.739\n",
      "0.74\n",
      "0.741\n",
      "0.742\n",
      "0.743\n",
      "0.744\n",
      "0.745\n",
      "0.746\n",
      "0.747\n",
      "0.748\n",
      "0.749\n",
      "0.75\n",
      "0.751\n",
      "0.752\n",
      "0.753\n",
      "0.754\n",
      "0.755\n",
      "0.756\n",
      "0.757\n",
      "0.758\n",
      "0.759\n",
      "0.76\n",
      "0.761\n",
      "0.762\n",
      "0.763\n",
      "0.764\n",
      "0.765\n",
      "0.766\n",
      "0.767\n",
      "0.768\n",
      "0.769\n",
      "0.77\n",
      "0.771\n",
      "0.772\n",
      "0.773\n",
      "0.774\n",
      "0.775\n",
      "0.776\n",
      "0.777\n",
      "0.778\n",
      "0.779\n",
      "0.78\n",
      "0.781\n",
      "0.782\n",
      "0.783\n",
      "0.784\n",
      "0.785\n",
      "0.786\n",
      "0.787\n",
      "0.788\n",
      "0.789\n",
      "0.79\n",
      "0.791\n",
      "0.792\n",
      "0.793\n",
      "0.794\n",
      "0.795\n",
      "0.796\n",
      "0.797\n",
      "0.798\n",
      "0.799\n",
      "0.8\n",
      "0.801\n",
      "0.802\n",
      "0.803\n",
      "0.804\n",
      "0.805\n",
      "0.806\n",
      "0.807\n",
      "0.808\n",
      "0.809\n",
      "0.81\n",
      "0.811\n",
      "0.812\n",
      "0.813\n",
      "0.814\n",
      "0.815\n",
      "0.816\n",
      "0.817\n",
      "0.818\n",
      "0.819\n",
      "0.82\n",
      "0.821\n",
      "0.822\n",
      "0.823\n",
      "0.824\n",
      "0.825\n",
      "0.826\n",
      "0.827\n",
      "0.828\n",
      "0.829\n",
      "0.83\n",
      "0.831\n",
      "0.832\n",
      "0.833\n",
      "0.834\n",
      "0.835\n",
      "0.836\n",
      "0.837\n",
      "0.838\n",
      "0.839\n",
      "0.84\n",
      "0.841\n",
      "0.842\n",
      "0.843\n",
      "0.844\n",
      "0.845\n",
      "0.846\n",
      "0.847\n",
      "0.848\n",
      "0.849\n",
      "0.85\n",
      "0.851\n",
      "0.852\n",
      "0.853\n",
      "0.854\n",
      "0.855\n",
      "0.856\n",
      "0.857\n",
      "0.858\n",
      "0.859\n",
      "0.86\n",
      "0.861\n",
      "0.862\n",
      "0.863\n",
      "0.864\n",
      "0.865\n",
      "0.866\n",
      "0.867\n",
      "0.868\n",
      "0.869\n",
      "0.87\n",
      "0.871\n",
      "0.872\n",
      "0.873\n",
      "0.874\n",
      "0.875\n",
      "0.876\n",
      "0.877\n",
      "0.878\n",
      "0.879\n",
      "0.88\n",
      "0.881\n",
      "0.882\n",
      "0.883\n",
      "0.884\n",
      "0.885\n",
      "0.886\n",
      "0.887\n",
      "0.888\n",
      "0.889\n",
      "0.89\n",
      "0.891\n",
      "0.892\n",
      "0.893\n",
      "0.894\n",
      "0.895\n",
      "0.896\n",
      "0.897\n",
      "0.898\n",
      "0.899\n",
      "0.9\n",
      "0.901\n",
      "0.902\n",
      "0.903\n",
      "0.904\n",
      "0.905\n",
      "0.906\n",
      "0.907\n",
      "0.908\n",
      "0.909\n",
      "0.91\n",
      "0.911\n",
      "0.912\n",
      "0.913\n",
      "0.914\n",
      "0.915\n",
      "0.916\n",
      "0.917\n",
      "0.918\n",
      "0.919\n",
      "0.92\n",
      "0.921\n",
      "0.922\n",
      "0.923\n",
      "0.924\n",
      "0.925\n",
      "0.926\n",
      "0.927\n",
      "0.928\n",
      "0.929\n",
      "0.93\n",
      "0.931\n",
      "0.932\n",
      "0.933\n",
      "0.934\n",
      "0.935\n",
      "0.936\n",
      "0.937\n",
      "0.938\n",
      "0.939\n",
      "0.94\n",
      "0.941\n",
      "0.942\n",
      "0.943\n",
      "0.944\n",
      "0.945\n",
      "0.946\n",
      "0.947\n",
      "0.948\n",
      "0.949\n",
      "0.95\n",
      "0.951\n",
      "0.952\n",
      "0.953\n",
      "0.954\n",
      "0.955\n",
      "0.956\n",
      "0.957\n",
      "0.958\n",
      "0.959\n",
      "0.96\n",
      "0.961\n",
      "0.962\n",
      "0.963\n",
      "0.964\n",
      "0.965\n",
      "0.966\n",
      "0.967\n",
      "0.968\n",
      "0.969\n",
      "0.97\n",
      "0.971\n",
      "0.972\n",
      "0.973\n",
      "0.974\n",
      "0.975\n",
      "0.976\n",
      "0.977\n",
      "0.978\n",
      "0.979\n",
      "0.98\n",
      "0.981\n",
      "0.982\n",
      "0.983\n",
      "0.984\n",
      "0.985\n",
      "0.986\n",
      "0.987\n",
      "0.988\n",
      "0.989\n",
      "0.99\n",
      "0.991\n",
      "0.992\n",
      "0.993\n",
      "0.994\n",
      "0.995\n",
      "0.996\n",
      "0.997\n",
      "0.998\n",
      "0.999\n",
      "1.0\n",
      "0.997\n",
      "0.994\n",
      "0.991\n",
      "0.988\n",
      "0.985\n",
      "0.982\n",
      "0.979\n",
      "0.976\n",
      "0.973\n",
      "0.97\n",
      "0.967\n",
      "0.964\n",
      "0.961\n",
      "0.958\n",
      "0.955\n",
      "0.952\n",
      "0.949\n",
      "0.946\n",
      "0.943\n",
      "0.94\n",
      "0.937\n",
      "0.934\n",
      "0.931\n",
      "0.928\n",
      "0.925\n",
      "0.922\n",
      "0.919\n",
      "0.916\n",
      "0.913\n",
      "0.91\n",
      "0.907\n",
      "0.904\n",
      "0.901\n",
      "0.898\n",
      "0.895\n",
      "0.892\n",
      "0.889\n",
      "0.886\n",
      "0.883\n",
      "0.88\n",
      "0.877\n",
      "0.874\n",
      "0.871\n",
      "0.868\n",
      "0.865\n",
      "0.862\n",
      "0.859\n",
      "0.856\n",
      "0.853\n",
      "0.85\n",
      "0.847\n",
      "0.844\n",
      "0.841\n",
      "0.838\n",
      "0.835\n",
      "0.832\n",
      "0.829\n",
      "0.826\n",
      "0.823\n",
      "0.82\n",
      "0.817\n",
      "0.814\n",
      "0.811\n",
      "0.808\n",
      "0.805\n",
      "0.802\n",
      "0.799\n",
      "0.796\n",
      "0.793\n",
      "0.79\n",
      "0.787\n",
      "0.784\n",
      "0.781\n",
      "0.778\n",
      "0.775\n",
      "0.772\n",
      "0.769\n",
      "0.766\n",
      "0.763\n",
      "0.76\n",
      "0.757\n",
      "0.754\n",
      "0.751\n",
      "0.748\n",
      "0.745\n",
      "0.742\n",
      "0.739\n",
      "0.736\n",
      "0.733\n",
      "0.73\n",
      "0.727\n",
      "0.724\n",
      "0.721\n",
      "0.718\n",
      "0.715\n",
      "0.712\n",
      "0.709\n",
      "0.706\n",
      "0.703\n",
      "0.7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f97d98d0908>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ket = SimulatedKettleEnv()\n",
    "ket.reset()\n",
    "for i in range(400):\n",
    "    result = ket.step(1)\n",
    "    print(result.reward)\n",
    "for i in range(400):\n",
    "    result = ket.step(0)\n",
    "plt.plot(ket.water_history)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resetting the kettle\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TimeStep(step_type=array(0, dtype=int32), reward=array(0., dtype=float32), discount=array(1., dtype=float32), observation=array([-0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3,\n",
       "       -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3,\n",
       "       -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3,\n",
       "       -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3,\n",
       "       -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3,\n",
       "       -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3,\n",
       "       -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3,\n",
       "       -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3,\n",
       "       -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3,\n",
       "       -0.3,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "        0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "        0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "        0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "        0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "        0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "        0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "        0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "        0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "        0. ,  0. ], dtype=float32))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation Spec:\n",
      "BoundedArraySpec(shape=(200,), dtype=dtype('float32'), name='observation', minimum=0.0, maximum=3.4028234663852886e+38)\n"
     ]
    }
   ],
   "source": [
    "print('Observation Spec:')\n",
    "print(env.time_step_spec().observation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward Spec:\n",
      "ArraySpec(shape=(), dtype=dtype('float32'), name='reward')\n"
     ]
    }
   ],
   "source": [
    "print('Reward Spec:')\n",
    "print(env.time_step_spec().reward)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action Spec:\n",
      "BoundedArraySpec(shape=(), dtype=dtype('int32'), name='action', minimum=0, maximum=1)\n"
     ]
    }
   ],
   "source": [
    "print('Action Spec:')\n",
    "print(env.action_spec())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_SIMULATION:\n",
    "    train_py_env = SimulatedKettleEnv()\n",
    "    eval_py_env = SimulatedKettleEnv()\n",
    "else:\n",
    "    train_py_env = KettleEnv()\n",
    "    eval_py_env = KettleEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_env = tf_py_environment.TFPyEnvironment(train_py_env)\n",
    "eval_env = tf_py_environment.TFPyEnvironment(eval_py_env)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_layer_params = (30,10,5)\n",
    "\n",
    "q_net = q_network.QNetwork(\n",
    "    train_env.observation_spec(),\n",
    "    train_env.action_spec(),\n",
    "    fc_layer_params=fc_layer_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.networks.q_network.QNetwork at 0x7f97d93b3ba8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "train_step_counter = tf.Variable(0)\n",
    "\n",
    "agent = dqn_agent.DqnAgent(\n",
    "    train_env.time_step_spec(),\n",
    "    train_env.action_spec(),\n",
    "    q_network=q_net,\n",
    "    optimizer=optimizer,\n",
    "    epsilon_greedy = 0.3,\n",
    "    td_errors_loss_fn=common.element_wise_huber_loss,\n",
    "    train_step_counter=train_step_counter)\n",
    "\n",
    "agent.initialize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_policy = agent.policy\n",
    "collect_policy = agent.collect_policy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_SIMULATION:\n",
    "    example_environment = tf_py_environment.TFPyEnvironment(SimulatedKettleEnv())\n",
    "else:\n",
    "    example_environment = tf_py_environment.TFPyEnvironment(KettleEnv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resetting the kettle\n"
     ]
    }
   ],
   "source": [
    "time_step = example_environment.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_avg_return(environment, policy, num_episodes=10):\n",
    "\n",
    "def compute_avg_return(environment, policy, num_steps = 100):\n",
    "\n",
    "  total_return = 0.0\n",
    "  for _ in range(num_episodes):\n",
    "\n",
    "    time_step = environment.reset()\n",
    "    episode_return = 0.0\n",
    "\n",
    "    while not time_step.is_last():\n",
    "      action_step = policy.action(time_step)\n",
    "      time_step = environment.step(action_step.action)\n",
    "      episode_return += time_step.reward\n",
    "    total_return += episode_return\n",
    "\n",
    "  avg_return = total_return / num_episodes\n",
    "  return avg_return.numpy()[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
    "    data_spec=agent.collect_data_spec,\n",
    "    batch_size=train_env.batch_size,\n",
    "    max_length=replay_buffer_max_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resetting the kettle\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def collect_step(environment, policy, buffer):\n",
    "  time_step = environment.current_time_step()\n",
    "  action_step = policy.action(time_step)\n",
    "  next_time_step = environment.step(action_step.action)\n",
    "  traj = trajectory.from_transition(time_step, action_step, next_time_step)\n",
    "\n",
    "  # Add trajectory to the replay buffer\n",
    "  buffer.add_batch(traj)\n",
    "\n",
    "def collect_data(env, policy, buffer, steps):\n",
    "  for _ in range(steps):\n",
    "    collect_step(env, policy, buffer)\n",
    "\n",
    "    \n",
    "random_policy = random_tf_policy.RandomTFPolicy(train_env.time_step_spec(), train_env.action_spec())\n",
    "collect_data(train_env, random_policy, replay_buffer, steps=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: (Trajectory(step_type=(16, 2), observation=(16, 2, 200), action=(16, 2), policy_info=(), next_step_type=(16, 2), reward=(16, 2), discount=(16, 2)), BufferInfo(ids=(16, 2), probabilities=(16,))), types: (Trajectory(step_type=tf.int32, observation=tf.float32, action=tf.int32, policy_info=(), next_step_type=tf.int32, reward=tf.float32, discount=tf.float32), BufferInfo(ids=tf.int64, probabilities=tf.float32))>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset generates trajectories with shape [Bx2x...]\n",
    "dataset = replay_buffer.as_dataset(\n",
    "    num_parallel_calls=3, \n",
    "    sample_batch_size=batch_size, \n",
    "    num_steps=2).prefetch(3)\n",
    "\n",
    "\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = iter(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reset the train step\n",
      "Evaluate the agent's policy once before training.\n",
      "step = 1000: loss = 0.22157081961631775, learning from 11000\n",
      "Temperature is 13.599999999999953\n",
      "step = 2000: loss = 0.24307942390441895, learning from 12000\n",
      "Temperature is 65.20000000000056\n",
      "step = 3000: loss = 0.2309722602367401, learning from 13000\n",
      "Temperature is 64.00000000000063\n",
      "step = 4000: loss = 0.26344847679138184, learning from 14000\n",
      "Temperature is 33.000000000000185\n",
      "Resetting the kettle\n",
      "Resetting the kettle\n",
      "step = 5000: loss = 0.3094533085823059, learning from 15000\n",
      "Temperature is 8.99999999999997\n",
      "Resetting the kettle\n",
      "Resetting the kettle\n",
      "Resetting the kettle\n",
      "Resetting the kettle\n",
      "step = 6000: loss = 0.24914319813251495, learning from 16000\n",
      "Temperature is 16.39999999999995\n",
      "Resetting the kettle\n",
      "Resetting the kettle\n",
      "Resetting the kettle\n",
      "step = 7000: loss = 0.46439069509506226, learning from 17000\n",
      "Temperature is 11.099999999999962\n",
      "Resetting the kettle\n",
      "Resetting the kettle\n",
      "Resetting the kettle\n",
      "step = 8000: loss = 0.40487393736839294, learning from 18000\n",
      "Temperature is 4.999999999999984\n",
      "Resetting the kettle\n",
      "Resetting the kettle\n",
      "Resetting the kettle\n",
      "Resetting the kettle\n",
      "step = 9000: loss = 0.6036292910575867, learning from 19000\n",
      "Temperature is 15.199999999999948\n",
      "Resetting the kettle\n",
      "Resetting the kettle\n",
      "Resetting the kettle\n",
      "step = 10000: loss = 0.412150502204895, learning from 20000\n",
      "Temperature is 9.09999999999997\n",
      "Resetting the kettle\n",
      "Resetting the kettle\n",
      "Resetting the kettle\n",
      "Resetting the kettle\n",
      "step = 11000: loss = 0.7394348978996277, learning from 21000\n",
      "Temperature is 18.69999999999998\n",
      "Resetting the kettle\n",
      "Resetting the kettle\n",
      "Resetting the kettle\n",
      "step = 12000: loss = 0.5473151206970215, learning from 22000\n",
      "Temperature is 9.199999999999969\n",
      "Resetting the kettle\n",
      "Resetting the kettle\n",
      "Resetting the kettle\n",
      "Resetting the kettle\n",
      "step = 13000: loss = 0.45946359634399414, learning from 23000\n",
      "Temperature is 18.399999999999977\n",
      "Resetting the kettle\n",
      "Resetting the kettle\n",
      "Resetting the kettle\n",
      "step = 14000: loss = 0.9815909266471863, learning from 24000\n",
      "Temperature is 10.499999999999964\n",
      "Resetting the kettle\n",
      "Resetting the kettle\n",
      "Resetting the kettle\n",
      "step = 15000: loss = 0.6159610748291016, learning from 25000\n",
      "Temperature is 0.3999999999999847\n",
      "Resetting the kettle\n",
      "Resetting the kettle\n",
      "Resetting the kettle\n",
      "Resetting the kettle\n",
      "step = 16000: loss = 0.516266942024231, learning from 26000\n",
      "Temperature is 14.199999999999951\n",
      "Resetting the kettle\n",
      "Resetting the kettle\n",
      "Resetting the kettle\n",
      "step = 17000: loss = 0.5956141948699951, learning from 27000\n",
      "Temperature is 5.299999999999983\n",
      "Resetting the kettle\n",
      "step = 18000: loss = 0.767932653427124, learning from 28000\n",
      "Temperature is 76.99999999999989\n",
      "Resetting the kettle\n",
      "step = 19000: loss = 0.5303864479064941, learning from 29000\n",
      "Temperature is 74.60000000000002\n",
      "Resetting the kettle\n",
      "step = 20000: loss = 0.8017175197601318, learning from 30000\n",
      "Temperature is 73.40000000000009\n",
      "Resetting the kettle\n",
      "step = 21000: loss = 1.3497382402420044, learning from 31000\n",
      "Temperature is 73.60000000000008\n",
      "Resetting the kettle\n",
      "step = 22000: loss = 0.9483569264411926, learning from 32000\n",
      "Temperature is 72.80000000000013\n",
      "Resetting the kettle\n",
      "step = 23000: loss = 1.7467560768127441, learning from 33000\n",
      "Temperature is 72.60000000000014\n",
      "Resetting the kettle\n",
      "step = 24000: loss = 1.654326319694519, learning from 34000\n",
      "Temperature is 74.00000000000006\n",
      "Resetting the kettle\n",
      "step = 25000: loss = 2.338467597961426, learning from 35000\n",
      "Temperature is 69.6000000000003\n",
      "Resetting the kettle\n",
      "step = 26000: loss = 2.6390466690063477, learning from 36000\n",
      "Temperature is 69.00000000000034\n",
      "Resetting the kettle\n",
      "step = 27000: loss = 2.017218828201294, learning from 37000\n",
      "Temperature is 68.80000000000035\n",
      "Resetting the kettle\n",
      "step = 28000: loss = 2.413985013961792, learning from 38000\n",
      "Temperature is 71.4000000000002\n",
      "Resetting the kettle\n",
      "step = 29000: loss = 2.816725730895996, learning from 39000\n",
      "Temperature is 70.60000000000025\n",
      "Resetting the kettle\n",
      "step = 30000: loss = 3.1951475143432617, learning from 40000\n",
      "Temperature is 70.60000000000025\n",
      "Resetting the kettle\n",
      "step = 31000: loss = 3.5986244678497314, learning from 41000\n",
      "Temperature is 66.60000000000048\n",
      "Resetting the kettle\n",
      "step = 32000: loss = 2.8164491653442383, learning from 42000\n",
      "Temperature is 66.00000000000051\n",
      "Resetting the kettle\n",
      "step = 33000: loss = 4.386055946350098, learning from 43000\n",
      "Temperature is 65.40000000000055\n",
      "Resetting the kettle\n",
      "step = 34000: loss = 5.077444076538086, learning from 44000\n",
      "Temperature is 64.80000000000058\n",
      "Resetting the kettle\n",
      "step = 35000: loss = 4.4453277587890625, learning from 45000\n",
      "Temperature is 62.2000000000006\n",
      "Resetting the kettle\n",
      "step = 36000: loss = 47.25675964355469, learning from 46000\n",
      "Temperature is 62.80000000000061\n",
      "Resetting the kettle\n",
      "step = 37000: loss = 5.226349830627441, learning from 47000\n",
      "Temperature is 60.60000000000058\n",
      "Resetting the kettle\n",
      "step = 38000: loss = 6.691737174987793, learning from 48000\n",
      "Temperature is 60.80000000000058\n",
      "Resetting the kettle\n",
      "step = 39000: loss = 5.867337703704834, learning from 49000\n",
      "Temperature is 62.2000000000006\n",
      "Resetting the kettle\n",
      "step = 40000: loss = 5.319840431213379, learning from 50000\n",
      "Temperature is 63.00000000000061\n",
      "Resetting the kettle\n",
      "step = 41000: loss = 4.904758930206299, learning from 51000\n",
      "Temperature is 61.40000000000059\n",
      "Resetting the kettle\n",
      "step = 42000: loss = 6.69756555557251, learning from 52000\n",
      "Temperature is 58.80000000000055\n",
      "Resetting the kettle\n",
      "step = 43000: loss = 6.350410461425781, learning from 53000\n",
      "Temperature is 57.20000000000053\n",
      "Resetting the kettle\n",
      "step = 44000: loss = 6.7400360107421875, learning from 54000\n",
      "Temperature is 59.20000000000056\n",
      "Resetting the kettle\n",
      "step = 45000: loss = 8.279071807861328, learning from 55000\n",
      "Temperature is 59.60000000000056\n",
      "Resetting the kettle\n",
      "step = 46000: loss = 11.336463928222656, learning from 56000\n",
      "Temperature is 55.2000000000005\n",
      "Resetting the kettle\n",
      "step = 47000: loss = 9.07555866241455, learning from 57000\n",
      "Temperature is 54.60000000000049\n",
      "Resetting the kettle\n",
      "step = 48000: loss = 9.18807315826416, learning from 58000\n",
      "Temperature is 55.80000000000051\n",
      "Resetting the kettle\n",
      "step = 49000: loss = 11.167892456054688, learning from 59000\n",
      "Temperature is 56.60000000000052\n",
      "Resetting the kettle\n",
      "step = 50000: loss = 7.514832496643066, learning from 60000\n",
      "Temperature is 56.200000000000514\n",
      "Resetting the kettle\n",
      "step = 51000: loss = 10.66997241973877, learning from 61000\n",
      "Temperature is 51.20000000000044\n",
      "Resetting the kettle\n",
      "step = 52000: loss = 9.090866088867188, learning from 62000\n",
      "Temperature is 50.20000000000043\n",
      "Resetting the kettle\n",
      "step = 53000: loss = 8.781387329101562, learning from 63000\n",
      "Temperature is 53.60000000000048\n",
      "Resetting the kettle\n",
      "step = 54000: loss = 15.2235107421875, learning from 64000\n",
      "Temperature is 57.20000000000053\n",
      "Resetting the kettle\n",
      "step = 55000: loss = 10.495443344116211, learning from 65000\n",
      "Temperature is 58.20000000000054\n",
      "Resetting the kettle\n"
     ]
    }
   ],
   "source": [
    "# (Optional) Optimize by wrapping some of the code in a graph using TF function.\n",
    "agent.train = common.function(agent.train)\n",
    "\n",
    "print(\"Reset the train step\")\n",
    "agent.train_step_counter.assign(0)\n",
    "\n",
    "print(\"Evaluate the agent's policy once before training.\")\n",
    "# avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
    "# returns = [avg_return]\n",
    "\n",
    "for current_iteration in range(num_iterations):\n",
    "#       agent.collect_policy._epsilon = 1.0\n",
    "#     try:\n",
    "    #   print(\"Collect a few steps using collect_policy and save to the replay buffer.\")\n",
    "      for _ in range(collect_steps_per_iteration):\n",
    "        collect_step(train_env, agent.collect_policy, replay_buffer)\n",
    "\n",
    "    #   print(\"Sample a batch of data from the buffer and update the agent's network.\")\n",
    "      experience, unused_info = next(iterator)\n",
    "      train_loss = agent.train(experience).loss\n",
    "      step = agent.train_step_counter.numpy()\n",
    "    #   print(\"Step is \", step)\n",
    "\n",
    "\n",
    "      if step % log_interval == 0:\n",
    "        print('step = {0}: loss = {1}, learning from {2}'.format(step, train_loss, replay_buffer.num_frames().numpy()))\n",
    "        print(\"Temperature is\", train_py_env.temperature_water)\n",
    "\n",
    "    #   if step % eval_interval == 0:\n",
    "    #     avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
    "    #     print('step = {0}: Average Return = {1}'.format(step, avg_return))\n",
    "    #     returns.append(avg_return)\n",
    "    #     except Exception as e:\n",
    "    #         print(\"Damn you kettle\")\n",
    "    #         print(e)\n",
    "    #         time.sleep(3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(replay_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blaat = next(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blaat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = KettleEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed = replay_buffer.gather_all().observation.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(observed[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(replay_buffer.gather_all().reward.numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
